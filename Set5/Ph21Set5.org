#+AUTHOR: Thomas Alford
#+LATEX_HEADER: \usepackage{amsthm}
#+LATEX_HEADER: \usepackage[margin=1.0in]{geometry}
#+LATEX_HEADER: \setlength{\parindent}{0pt}
#+LATEX_HEADER: \setlength{\parskip}{\baselineskip}
#+OPTIONS: toc:nil
#+OPTIONS: num:nil
#+TITLE: Ph21 Problem Set 4
* Problem 1
** Imports
#+BEGIN_SRC ipython :session  kernel-689.json :exports both :results raw drawer
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
import dynesty
from dynesty import plotting as dyplot
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[119]:
:END:

** Previous Code

#+BEGIN_SRC ipython :session  kernel-689.json :exports both :results raw drawer
def biased_flip(H, size=None):
    return np.random.random(size=size) < H

def get_H_vals(H):
    nval = 1024
    bflips = biased_flip(H, size=nval)
    sum_val = np.sum(bflips)
    return sum_val, nval

def get_H_prob(n, h, H):
    if (H <= 0 or H >= 1):
        return 0
    return (np.math.factorial(n) / (np.math.factorial(h) * np.math.factorial(
        n - h))) * H ** h * (1 - H) ** (n - h)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[355]:
:END:

** MCMC Runs

At this point in using Dynesty the main parameters to vary are nlive and
dlogz. nlive increases the number of live points, which gives a more accurate
posterior but requires more iterations to converge. dlogz is the change in
log-likelihood between samples at which we stop. So, smaller values result in
more iterations.

#+BEGIN_SRC ipython :session  kernel-689.json :exports both :results raw drawer
def plot_H_probs(real_H, sampler_results, prior_func, dlogz, **prior_kwargs):
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 7))
    ax1.plot(sampler_results.samples, np.exp(sampler_results.logl), '.',
            label='n=1024')
    H_vals = np.linspace(0, 1, 1000)
    prior_vals = np.array([prior_func(H, **prior_kwargs) for H in H_vals])
    normed_vals = prior_vals * (np.max(np.exp(
        sampler_results.logl)) / np.max(prior_vals))
    ax1.plot(H_vals, normed_vals, '--', label='prior')
    ax1.set_ylabel('likelihood')
    ax1.legend()

    ax2.hist(sampler_results.samples, density=True, bins=1000)
    #ax2.set_xlabel('H')
    ax2.set_ylabel('sample density')

    plt.suptitle('Posterior probabilities of H with real H = %s and '
                 'dlogz = %s' % (real_H, dlogz))
    fig.text(0.5, 0.04, 'Number of Heads', ha='center')
    #fig.text(0.04, 0.5, 'Posterior Density', va='center', rotation='vertical')
    plt.subplots_adjust(top=0.9, hspace=.6)
    plt.show()

def get_and_plot_H(H, prior_func, dlogz_val, **prior_kwargs):
    sum_val, nval = get_H_vals(H)

    def loglike(H):
        return np.log(get_H_prob(nval, sum_val, H[0]))

    def ptform(u):
        return u

    ndim = 1
    sampler = dynesty.DynamicNestedSampler(loglike, ptform, ndim,
                                           bound='single', nlive=50) 

    sampler.run_nested(dlogz_init=dlogz_val, print_progress=False)
    results = sampler.results
    plot_H_probs(H, results, prior_func, dlogz_val, **prior_kwargs)
    return results.samples[-1, 0]
    
def uniform_prior(H):
    return 1
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[344]:
:END:

*** Uniform Priors

**** Testing Nlive

#+BEGIN_SRC ipython :session  kernel-689.json :exports both :results raw drawer
maxL = get_and_plot_H(.5, uniform_prior, 1)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[38]:
[[file:./obipy-resources/692k2F.png]]
:END:

#+BEGIN_SRC ipython :session  kernel-689.json :exports both :results output
print(maxL)
#+END_SRC

#+RESULTS:
: 0.4853515938554689

Now let's try doing this for a lower value of dlogz:

#+BEGIN_SRC ipython :session  kernel-689.json :exports both :results raw drawer
maxL = get_and_plot_H(.8, uniform_prior, .01)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[41]:
[[file:./obipy-resources/692xAM.png]]
:END:

#+BEGIN_SRC ipython :session  kernel-689.json :exports both :results output
print(maxL)
#+END_SRC

#+RESULTS:
: 0.7929687534700439

Now we can start working non-uniform priors:

*** Gaussian Priors

#+BEGIN_SRC ipython :session  kernel-689.json :exports both :results raw drawer
def gaussian(x, mu=0, sigma=1, C=1):
    return C * np.exp((-(x - mu) ** 2) / (2 * sigma ** 2))
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[6]:
:END:

#+BEGIN_SRC ipython :session  kernel-689.json :exports both :results raw drawer
get_and_plot_H(.5, gaussian, .1, mu=.5, sigma=.25)
plt.show()
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[45]:
[[file:./obipy-resources/692-KS.png]]
:END:

#+BEGIN_SRC ipython :session  kernel-689.json :exports both :results raw drawer
get_and_plot_H(.7, gaussian, .1, mu=.5, sigma=.25)
plt.show()
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[46]:
[[file:./obipy-resources/692LVY.png]]
:END:

#+BEGIN_SRC ipython :session  kernel-689.json :exports both :results raw drawer
get_and_plot_H(.7, gaussian, .1, mu=.3, sigma=.1)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[47]:
: 0.7128881085635415
[[file:./obipy-resources/692Yfe.png]]
:END:

* Problem 2
 Now we'll look at the lighthouse problem again:

** Methods from Previous Set 

#+BEGIN_SRC ipython :session  kernel-689.json :exports both :results raw drawer
def rand_angle(size=None):
    return np.random.random(size=size) * np.pi - np.pi / 2

def get_theta(d, alpha, beta):
    return np.arctan((d - alpha) / beta)

def get_prob(d, alpha, beta):
    # assume d has been rounded to two places i.e. 1.22
    # range is then 1.215 to 1.225
    high_bound = get_theta(d + .005, alpha, beta)
    low_bound = get_theta(d - .005, alpha, beta)
    diff = np.abs(high_bound - low_bound)
    # this is basically our unnormalized probability
    return diff
    
def get_rand_locs(nlocs, alpha, beta):
    angles = rand_angle(size=nlocs)
    # have that alpha - loc = beta * tan(theta)
    diff = beta * np.tan(angles)
    loc = alpha - diff
    return loc

def get_log_likelihood(rounded_data, alpha, beta):
    log_like = np.sum(np.log(np.array(
        [get_prob(d, alpha, beta) for d in rounded_data])))
    return log_like
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[332]:
:END:

** MCMC Runs

#+BEGIN_SRC ipython :session  kernel-689.json :exports both :results raw drawer
def plot_lighthouse_corner(results):
    fig = plt.subplots(2, 2, figsize=(10, 6))
    dyplot.cornerplot(results, fig=fig)
    fig[1][1, 0].set_ylabel(r'$\beta$')
    fig[1][1, 0].set_xlabel(r'$\alpha$')
    fig[1][1, 1].set_xlabel(r'$\beta$')
    plt.tight_layout()
    plt.show()

def plot_lighthouse_scatter(results):
    fig = plt.subplots(1, 1, figsize=(8, 5))
    dyplot.cornerpoints(results, fig=fig)
    fig[1].set_ylabel(r'$\beta$')
    fig[1].set_xlabel(r'$\alpha$')
    plt.tight_layout()
    plt.xlim(-10, 10)
    plt.ylim(0, 10)
    plt.show()

def plot_traceplot(results):
    fig = plt.subplots(2, 2, figsize=(10, 6))
    dyplot.traceplot(results, fig=fig)
    fig[1][1, 1].set_xlabel(r'$\beta$')
    fig[1][0, 1].set_xlabel(r'$\alpha$')
    fig[1][1, 0].set_ylabel(r'$\beta$')
    fig[1][0, 0].set_ylabel(r'$\alpha$')
    plt.tight_layout()
    plt.show()

def plot_runplot(results):
    dyplot.runplot(results)
    plt.show()
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[292]:
:END:

#+BEGIN_SRC ipython :session  kernel-689.json :exports both :results raw drawer
def get_grid_posts(n, alpha, beta, dlogz_val=.1, interloper=False, d=1):
    locs = np.round(get_rand_locs(n, alpha, beta), 2)
    if (interloper):
        interloper_locs= np.round(get_rand_locs(n, alpha + d, beta - d), 2)
        locs = np.append(locs, interloper_locs)
    
    def lighthouse_logl(params):
        return get_log_likelihood(locs, params[0], params[1])
    
    # here we'll really just keep it uniform from (-100, 100)
    def ptform(u):
        return [2000 * u[0] - 1000, 1000 * u[1]]

    ndim = 2
    sampler = dynesty.NestedSampler(lighthouse_logl, ptform, ndim,
                                           bound='single', nlive=500) 

    sampler.run_nested(dlogz=dlogz_val, print_progress=False)
    return sampler.results
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[356]:
:END:

First we'll just look at the original lighthouse problem:

#+BEGIN_SRC ipython :session  kernel-689.json :exports both :results raw drawer
results = get_grid_posts(500, 0, 5)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[346]:
:END:

#+BEGIN_SRC ipython :session  kernel-689.json :exports both :results raw drawer
plot_lighthouse_corner(results)
plt.show()
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[347]:
[[file:./obipy-resources/692Ghy.png]]
:END:

#+BEGIN_SRC ipython :session  kernel-689.json :exports both :results raw drawer
plot_lighthouse_scatter(results)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[348]:
[[file:./obipy-resources/6924qB.png]]
:END:

#+BEGIN_SRC ipython :session  kernel-689.json :exports both :results raw drawer
plot_traceplot(results)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[349]:
[[file:./obipy-resources/692F1H.png]]
:END:

#+BEGIN_SRC ipython :session  kernel-689.json :exports both :results raw drawer
plot_runplot(results)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[350]:
[[file:./obipy-resources/692S_N.png]]
:END:

#+BEGIN_SRC ipython :session  kernel-689.json :exports both :results raw drawer
results.samples[-1]
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[351]:
: array([0.03130404, 5.18680251])
:END:

Here we see that we get pretty close to the 'correct' values of (0, 5).

Now let's try looking at the interloper case located at (1, 4):

#+BEGIN_SRC ipython :session  kernel-689.json :exports both :results raw drawer
interloper_results = get_grid_posts(500, 0, 5, interloper=True)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[352]:
:END:

#+BEGIN_SRC ipython :session  kernel-689.json :exports both :results raw drawer
plot_lighthouse_corner(interloper_results)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[353]:
[[file:./obipy-resources/692fJU.png]]
:END:

Here we see that it's pretty hard to actually splot this interloper
here. Instead the \alpha and \beta values are just in-between the two values of
the original lighthouse and interloper.

Maybe a larger discrepancy between original and interloper would be better,
this time with the original located at (0, 7) and the interloper located at (5,
2):

#+BEGIN_SRC ipython :session  kernel-689.json :exports both :results raw drawer
larger_interloper_results = get_grid_posts(500, 0, 7, interloper=True, d=5)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[357]:
:END:

#+BEGIN_SRC ipython :session  kernel-689.json :exports both :results raw drawer
plot_lighthouse_corner(larger_interloper_results)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[358]:
[[file:./obipy-resources/692sTa.png]]
:END:

Here we also are unable to find this interloper. Even weirder is the fact that
our \alpha and \beta values are not even near the means of the values of the
two lighthouses: \alpha is above while \beta is below.
